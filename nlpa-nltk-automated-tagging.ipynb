{
 "metadata": {
  "name": "nlpa-nltk-automated-tagging"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import urllib2\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Automatic Tagging with NLTK"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Although the above results are neat, they aren't all that useful in practice\n",
      "because most texts we want to visualize in such ways aren't tagged, and tagging\n",
      "them by hand ist costly.\n",
      "\n",
      "What we need is an *automated tagger*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take a page off Wikipedia and tag it automatically."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opener = urllib2.build_opener()\n",
      "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
      "infile = opener.open('http://en.wikipedia.org/w/index.php?title=George_Washington&printable=yes')\n",
      "page = infile.read().decode(\"utf-8\")\n",
      "page[:400]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "u'<!DOCTYPE html>\\n<html lang=\"en\" dir=\"ltr\" class=\"client-nojs\">\\n<head>\\n<title>George Washington - Wikipedia, the free encyclopedia</title>\\n<meta charset=\"UTF-8\" />\\n<meta name=\"generator\" content=\"MediaWiki 1.21wmf4\" />\\n<meta name=\"robots\" content=\"noindex,follow\" />\\n<link rel=\"apple-touch-icon\" href=\"//en.wikipedia.org/apple-touch-icon.png\" />\\n<link rel=\"shortcut icon\" href=\"/favicon.ico\" />\\n<link '"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is in HTML format, so we first need to clean it up.\n",
      "\n",
      "(There are other ways of cleaning up and analyzing HTML.\n",
      "A good HTML library is BeautifulSoup.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "page = nltk.util.clean_html(page)\n",
      "page = re.sub(r'\\s*\\n+','\\n',page)\n",
      "print page[:400]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "George Washington - Wikipedia, the free encyclopedia\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t George Washington\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t From Wikipedia, the free encyclopedia\n",
        "\t\t\t\t\tJump to:\t\t\t\t\t navigation , \t\t\t\t\t search\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t This article is about the first President of the United States. For other uses, see George Washington (disambiguation) .\n",
        " For a simpler version of this article, see the Simple English Wikipedia article: \n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All the rest of the software works on tokenized data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents = nltk.sent_tokenize(page)\n",
      "sents = [nltk.word_tokenize(s) for s in sents]\n",
      "print sents[17]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'Washington', u'quickly', u'became', u'a', u'senior', u'officer', u'in', u'the', u'colonial', u'forces', u'during', u'the', u'first', u'stages', u'of', u'the', u'French', u'and', u'Indian', u'War', u'.']\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This data hasn't been manually tagged, so we need an automatic tagger."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.pos_tag(sents[17])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'Washington', 'NNP'), (u'quickly', 'RB'), (u'became', 'VBD'), (u'a', 'DT'), (u'senior', 'JJ'), (u'officer', 'NN'), (u'in', 'IN'), (u'the', 'DT'), (u'colonial', 'JJ'), (u'forces', 'NNS'), (u'during', 'IN'), (u'the', 'DT'), (u'first', 'JJ'), (u'stages', 'NNS'), (u'of', 'IN'), (u'the', 'DT'), (u'French', 'JJ'), (u'and', 'CC'), (u'Indian', 'JJ'), (u'War', 'NN'), (u'.', '.')]\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To perform named entity extraction, we run `ne_chunk` on the output of `pos_tag`.\n",
      "\n",
      "The output is a mix of tree nodes combining multiple tagged words,\n",
      "together with raw tagged words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunked = nltk.ne_chunk(nltk.pos_tag(sents[17]))\n",
      "for node in chunked:\n",
      "    print node"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(GPE Washington/NNP)\n",
        "(u'quickly', 'RB')\n",
        "(u'became', 'VBD')\n",
        "(u'a', 'DT')\n",
        "(u'senior', 'JJ')\n",
        "(u'officer', 'NN')\n",
        "(u'in', 'IN')\n",
        "(u'the', 'DT')\n",
        "(u'colonial', 'JJ')\n",
        "(u'forces', 'NNS')\n",
        "(u'during', 'IN')\n",
        "(u'the', 'DT')\n",
        "(u'first', 'JJ')\n",
        "(u'stages', 'NNS')\n",
        "(u'of', 'IN')\n",
        "(u'the', 'DT')\n",
        "(GPE French/JJ)\n",
        "(u'and', 'CC')\n",
        "(GPE Indian/JJ)\n",
        "(u'War', 'NN')\n",
        "(u'.', '.')\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are actually several different kinds of named entities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "ORGANIZATION\tGeorgia-Pacific Corp., WHO\n",
      "PERSON\t      Eddy Bonte, President Obama\n",
      "LOCATION\t    Murray River, Mount Everest\n",
      "DATE\t        June, 2008-06-29\n",
      "TIME\t        two fifty a m, 1:30 p.m.\n",
      "MONEY\t       175 million Canadian Dollars, GBP 10.40\n",
      "PERCENT\t     twenty pct, 18.75 %\n",
      "FACILITY\t    Washington Monument, Stonehenge\n",
      "GPE\t         South East Asia, Midlothian\n",
      "\"\"\";None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now need to dig through this data to extract the actual information about\n",
      "the named entity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nextract(tokens,types=[\"GPE\",\"PERSON\"]):\n",
      "    chunked = nltk.ne_chunk(nltk.pos_tag(tokens))\n",
      "    return [c for c in chunked if hasattr(c,\"node\") and c.node in types]\n",
      "nes = nextract(sents[17])\n",
      "nes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "[Tree('GPE', [(u'Washington', 'NNP')]),\n",
        " Tree('GPE', [(u'French', 'JJ')]),\n",
        " Tree('GPE', [(u'Indian', 'JJ')])]"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nes[0].leaves()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "[(u'Washington', 'NNP')]"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nextract_text(tokens,types=[\"GPE\",\"PERSON\"]):\n",
      "    nodes = nextract(tokens,types)\n",
      "    return [\" \".join(c[0] for c in chunk.leaves()) for chunk in nodes]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nextract_text(sents[17])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "[u'Washington', u'French', u'Indian']"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nes = [nextract_text(s,[\"PERSON\"]) for s in sents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at what this extracted."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "Counter([x for l in nes for x in l]).most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "[(u'George Washington', 90),\n",
        " (u'George', 44),\n",
        " (u'Mount Vernon', 22),\n",
        " (u'Martha', 14),\n",
        " (u'Jefferson', 8),\n",
        " (u'Chernow', 8),\n",
        " (u'John Adams', 8),\n",
        " (u'See', 7),\n",
        " (u'Oxford University', 6),\n",
        " (u'John', 6)]"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, the named entity extractor has a significant error rate.\n",
      "\"Mount Vernon\", \"See\", and \"Oxford University\" are not  persons.\n",
      "Also, we don't know the identity of \"George\", \"Martha\", and \"John\".\n",
      "But generally, it seems to return the right thing."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's look at co-occurences of named entities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import *\n",
      "pairs = Counter([tuple(sorted(list(p))) for s in nes for p in combinations(s,2)])\n",
      "[p for p in pairs.most_common(20) if p[0][0]!=p[0][1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "[((u'George Washington', u'Mount Vernon'), 17),\n",
        " ((u'George Washington', u'Lawrence Washington'), 12),\n",
        " ((u'John Adams', u'Position'), 10),\n",
        " ((u'George Washington', u'Henry Knox'), 8),\n",
        " ((u'George Washington', u'Henry Compton'), 8),\n",
        " ((u'George Washington', u'Martha Washington'), 8),\n",
        " ((u'George Washington', u'John Adams'), 8),\n",
        " ((u'George Washington', u'William Wake'), 8),\n",
        " ((u'George Washington', u'John Tyler'), 8),\n",
        " ((u'George Washington', u'Gibson'), 8),\n",
        " ((u'George Washington', u'William &amp'), 8),\n",
        " ((u'George Washington', u'Timothy Pickering'), 8),\n",
        " ((u'Gardens Discover', u'George Washington'), 7),\n",
        " ((u'George Washington', u'George Washington Birthplace National Monument'),\n",
        "  7),\n",
        " ((u'George Washington', u'Mount Vernon Estate'), 7),\n",
        " ((u'George Washington', u'Miller Center'), 7),\n",
        " ((u'George Washington', u'Museum &amp'), 7),\n",
        " ((u'George Washington', u'Made George Washington'), 7)]"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}