{
 "metadata": {
  "name": "nlpa-classifier-sentence-segmentation"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.corpus import names\n",
      "from pylab import *\n",
      "import random as pyrandom"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sentence Segmentation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents = nltk.corpus.treebank_raw.sents()\n",
      "sents = [s for s in sents if len(s)>3]\n",
      "sents = [s for s in sents if \"START\" not in s]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = []\n",
      "boundaries = []\n",
      "for s in sents:\n",
      "    tokens += s\n",
      "    boundaries.append(len(tokens)-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tokens[:200]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov', '.', '29', '.', 'Mr', '.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N', '.', 'V', '.,', 'the', 'Dutch', 'publishing', 'group', '.', 'Rudolph', 'Agnew', ',', '55', 'years', 'old', 'and', 'former', 'chairman', 'of', 'Consolidated', 'Gold', 'Fields', 'PLC', ',', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'British', 'industrial', 'conglomerate', '.', 'A', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'Kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of', 'workers', 'exposed', 'to', 'it', 'more', 'than', '30', 'years', 'ago', ',', 'researchers', 'reported', '.', 'The', 'asbestos', 'fiber', ',', 'crocidolite', ',', 'is', 'unusually', 'resilient', 'once', 'it', 'enters', 'the', 'lungs', ',', 'with', 'even', 'brief', 'exposures', 'to', 'it', 'causing', 'symptoms', 'that', 'show', 'up', 'decades', 'later', ',', 'researchers', 'said', '.', 'Lorillard', 'Inc', '.,', 'the', 'unit', 'of', 'New', 'York', '-', 'based', 'Loews', 'Corp', '.', 'that', 'makes', 'Kent', 'cigarettes', ',', 'stopped', 'using', 'crocidolite', 'in', 'its', 'Micronite', 'cigarette', 'filters', 'in', '1956', '.', 'Although', 'preliminary', 'findings', 'were', 'reported', 'more', 'than', 'a', 'year', 'ago', ',', 'the', 'latest', 'results', 'appear', 'in', 'today', \"'\", 's', 'New', 'England', 'Journal', 'of', 'Medicine', ',', 'a', 'forum', 'likely', 'to', 'bring', 'new', 'attention', 'to', 'the', 'problem', '.', 'A', 'Lorillard', 'spokewoman', 'said', ',', '\"']\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def features(s,i):\n",
      "    return dict(current=tokens[i],\n",
      "                prev=tokens[i-1],\n",
      "                next=tokens[i+1],\n",
      "                upper=tokens[i+1][0].isupper(),\n",
      "                plen=len(tokens[i-1]),\n",
      "                nlen=len(tokens[i+1]))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = []\n",
      "for i in range(1,len(tokens)-1):\n",
      "    if tokens[i] not in [\".\",\"?\",\"!\"]: continue\n",
      "    c = (i in boundaries)\n",
      "    f = features(tokens,i)\n",
      "    data.append((f,c))\n",
      "pyrandom.shuffle(data)\n",
      "n = len(data)\n",
      "print n\n",
      "training_set = data[n//10:]\n",
      "test_set = data[:n//10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5951\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
      "nltk.classify.accuracy(classifier,test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "0.9798319327731092"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier.classify(features(\"The quick . brown\".split(),2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def segment_sentences(words):\n",
      "    sentences = [[words[0]]]\n",
      "    for i in range(1,len(words)):\n",
      "        sentences[-1].append(words[i])\n",
      "        c = words[i] in [\".\",\"?\",\"!\"] and classifier.classify(features(words,i))\n",
      "        if c: sentences.append([])\n",
      "    if sentences[-1]==[]: sentences = sentences[:-1]\n",
      "    return sentences\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segment_sentences(\"\"\"Smith ran . J . Smith really ran . \"\"\".split())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "[['Smith', 'ran', '.'], ['J', '.', 'Smith', 'really', 'ran', '.']]"
       ]
      }
     ],
     "prompt_number": 61
    }
   ],
   "metadata": {}
  }
 ]
}